{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sokwry1Xjj6R"
   },
   "outputs": [],
   "source": [
    "from utils import harris, dist2, find_sift\n",
    "from PIL import Image\n",
    "from skimage.feature import plot_matches\n",
    "from skimage.transform import ProjectiveTransform, warp\n",
    "from scipy.linalg import svd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import skimage\n",
    "import numpy as np\n",
    "# add your imports below"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Q1R0wybFj_Hx"
   },
   "source": [
    "## 1. Load images and Convert to grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5OP41FY8afY1"
   },
   "outputs": [],
   "source": [
    "img1 = Image.open('hw2_data/uttower_left.JPG').convert('L')# \n",
    "img2 = Image.open('hw2_data/uttower_right.JPG').convert('L')#\n",
    "\n",
    "img1_float = np.array(img1, dtype = np.float32) \n",
    "img2_float = np.array(img2, dtype = np.float32) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vspyM9ruasVa"
   },
   "outputs": [],
   "source": [
    "plt.imshow(img1, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gSz1dfv8ayLI"
   },
   "outputs": [],
   "source": [
    "plt.imshow(img2, cmap='gray')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "oYGWoN47kLZe"
   },
   "source": [
    "## 2. Detect Feature Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YTAlo9Ara91e"
   },
   "outputs": [],
   "source": [
    "sigma = 3.0\n",
    "thresh = 50.0\n",
    "radius = 3.0\n",
    "# use harris from utils.py\n",
    "cim1, r1, c1 = harris(img1_float, sigma, thresh, radius)#\n",
    "cim2, r2, c2 = harris(img2_float, sigma, thresh, radius)#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vkrb5aNtb3Ct"
   },
   "outputs": [],
   "source": [
    "plt.imshow(cim1, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s1tfDPGXb_Ot"
   },
   "outputs": [],
   "source": [
    "plt.imshow(cim2, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cVsf3zRUKdVM"
   },
   "outputs": [],
   "source": [
    "def draw_corners(img, r, c):\n",
    "    img_copy = img.copy()\n",
    "    fig, ax = plt.subplots(figsize = (10, 10))\n",
    "    for i in range(0, len(r)):\n",
    "        rect = patches.Rectangle((c[i], r[i]), 10, 10, linewidth=1, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "    ax.imshow(img_copy, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s5_fuDz1LT2f"
   },
   "outputs": [],
   "source": [
    "draw_corners(img1, r1, c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g2PYJ7F8LT_W"
   },
   "outputs": [],
   "source": [
    "draw_corners(img2, r2, c2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "e6kfCi_vkSYn"
   },
   "source": [
    "## 3. Extract local neighborhoods around every keypoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neighbor_descriptors(img, r, c, radius):\n",
    "    descriptors = []\n",
    "    size = 2 * radius + 1\n",
    "    height, width = img.shape\n",
    "    for y, x in zip(r, c):\n",
    "        y_min = max(y - radius, 0)\n",
    "        y_max = min(y + radius + 1, height)\n",
    "        x_min = max(x - radius, 0)\n",
    "        x_max = min(x + radius + 1, width)\n",
    "        patch = img[y_min:y_max, x_min:x_max]\n",
    "        y_top = max(radius - y, 0)\n",
    "        y_bottom = max(y + radius + 1 - height, 0)\n",
    "        x_left = max(radius - x, 0)\n",
    "        x_right = max(x + radius + 1 - width, 0)\n",
    "        patch = np.pad(patch, ((y_top, y_bottom), (x_left, x_right)), mode='constant')\n",
    "        descriptor = patch.reshape(-1)\n",
    "        descriptors.append(descriptor)\n",
    "    return np.array(descriptors)\n",
    "\n",
    "def normalize(mat):\n",
    "    row_means = np.mean(mat, axis=1, keepdims=True)\n",
    "    row_stds = np.std(mat, axis=1, keepdims=True)\n",
    "    normalized_matrix = (mat - row_means) / (row_stds + 1e-8)\n",
    "\n",
    "    return normalized_matrix\n",
    "\n",
    "descriptors_1 = neighbor_descriptors(img1_float, r1, c1, radius=10)\n",
    "descriptors_2 = neighbor_descriptors(img2_float, r2, c2, radius=10)\n",
    "\n",
    "descriptors_1 = normalize(descriptors_1)\n",
    "descriptors_2 = normalize(descriptors_2)\n",
    "print(len(r1))\n",
    "print(descriptors_1)\n",
    "print(descriptors_1.shape)\n",
    "print(\"\\n\")\n",
    "print(len(r2))\n",
    "print(descriptors_2.shape)\n",
    "print(descriptors_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sift_descriptors(img, r, c, radius):\n",
    "    r = r.reshape(-1, 1)\n",
    "    c = c.reshape(-1, 1)  \n",
    "    radius = np.full_like(r, radius)  \n",
    "    circles = np.hstack([c, r, radius])  \n",
    "    return find_sift(img, circles)\n",
    "\n",
    "\n",
    "descriptors_1 = sift_descriptors(img1_float, r1, c1, 3)\n",
    "descriptors_2 = sift_descriptors(img2_float, r2, c2, 3)\n",
    "print(descriptors_1.shape)\n",
    "print(descriptors_1)\n",
    "\n",
    "print(descriptors_2.shape)\n",
    "print(descriptors_2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "lVMhquCNkbO_"
   },
   "source": [
    "## 4. Compute distances between descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3-0c-frcdI0R"
   },
   "outputs": [],
   "source": [
    "# use dist2 from utils.py to compute dist between descriptors\n",
    "distances = dist2(descriptors_2, descriptors_1)#\n",
    "print(distances)\n",
    "print(distances.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "gdMfzIR3ki1w"
   },
   "source": [
    "## 5. Select Matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_descriptors_by_dist(distances, thresh):\n",
    "    matches = []\n",
    "    for i in range(distances.shape[0]):\n",
    "        for j in range(distances.shape[1]):\n",
    "            if distances[i][j] < thresh:\n",
    "                matches.append((i, j))\n",
    "    return np.array(matches)\n",
    "\n",
    "print(np.max(distances))\n",
    "thresh = np.sort(distances.flatten())[100]\n",
    "\n",
    "print(thresh)\n",
    "\n",
    "filtered_matches = filter_descriptors_by_dist(distances, thresh)\n",
    "\n",
    "def plot_matches(img1, img2, r1, c1, r2, c2, matches):\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1)\n",
    "    img = np.concatenate((img1, img2), axis=1)\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    for i, j in matches:\n",
    "        ax.plot([c1[i], c2[j] + img1.shape[1]], [r1[i], r2[j]], 'r')\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "print(len(filtered_matches))\n",
    "plot_matches(img1_float, img2_float, r1, c1, r2, c2, filtered_matches)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "YPn3apR0kx_Q"
   },
   "source": [
    "## 6. RANSAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oysrwFKKeWF2"
   },
   "outputs": [],
   "source": [
    "def RANSAC(filtered_matches, eps, num_loops):\n",
    "    best_homography = None\n",
    "    best_inliers = []\n",
    "    best_residual = 0\n",
    "\n",
    "    for _ in range(num_loops):\n",
    "        sample_indices = np.random.choice(range(len(filtered_matches)), 4)\n",
    "        \n",
    "        src_points = np.array([[c1[i], r1[i]] for i, _ in filtered_matches[sample_indices]])\n",
    "        dst_points = np.array([[c2[j], r2[j]] for _, j in filtered_matches[sample_indices]])\n",
    "\n",
    "\n",
    "        homography = estimate_homography(src_points, dst_points)\n",
    "        inliers, residual = count_inliers(filtered_matches, homography, eps)\n",
    "\n",
    "        if len(inliers) > len(best_inliers):\n",
    "            best_homography = homography\n",
    "            best_inliers = inliers\n",
    "            best_residual = residual\n",
    "\n",
    "    return best_inliers, best_residual, best_homography\n",
    "\n",
    "def estimate_homography(src_points, dst_points):\n",
    "    num_points = src_points.shape[0]\n",
    "    A = np.zeros((2 * num_points, 9))\n",
    "\n",
    "    for i in range(num_points):\n",
    "        x, y = src_points[i]\n",
    "        u, v = dst_points[i]\n",
    "        A[2 * i] = [-x, -y, -1, 0, 0, 0, x * u, y * u, u]\n",
    "        A[2 * i + 1] = [0, 0, 0, -x, -y, -1, x * v, y * v, v]\n",
    "\n",
    "    _, _, V = svd(A)\n",
    "    H = V[-1].reshape((3, 3))\n",
    "\n",
    "    return H\n",
    "\n",
    "def count_inliers(matches, homography, eps):\n",
    "    inliers = []\n",
    "    residual = 0\n",
    "    for i, j in matches:\n",
    "        src_point = np.array([c1[i], r1[i], 1])\n",
    "        dst_point = np.array([c2[j], r2[j]])\n",
    "        transformed_src = homography.dot(src_point)\n",
    "        \n",
    "        if np.isclose(transformed_src[2], 0):\n",
    "            continue\n",
    "\n",
    "        transformed_src /= transformed_src[2]\n",
    "        error = np.linalg.norm(transformed_src[:2] - dst_point)\n",
    "        \n",
    "        if error <= eps:\n",
    "            inliers.append([i, j])\n",
    "            residual += error\n",
    "\n",
    "    return np.array(inliers), residual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a0KLZ4IEiYdi"
   },
   "outputs": [],
   "source": [
    "# report num of inliers and the average residual for the inliers\n",
    "inliers, residual, H = RANSAC(filtered_matches, 2, 10000)\n",
    "print(\"number of inliers: \" + str(len(inliers)))\n",
    "print(\"residual: \" + str(residual))\n",
    "\n",
    "# display the locations of inlier matches in both images\n",
    "plot_matches(img1_float, img2_float, r1, c1, r2, c2, inliers)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "vXmm6ZGLk4T7"
   },
   "source": [
    "## 7. Warp one image onto the other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QtSmiTeMfSR8"
   },
   "outputs": [],
   "source": [
    "def warp_img(image_left, H):\n",
    "    # this part of code is referenced from Ajinkya Tejankar\n",
    "    # get the height and width of the image\n",
    "    # this function will work with color images\n",
    "    # so, having third color channel is not a problem\n",
    "    h_left, w_left = image_left.shape[:2]\n",
    "\n",
    "    # we want to find where the image corners are going to land\n",
    "    # so, we create a matrix of four corner points\n",
    "    C_left = np.array([\n",
    "        [0, 0     , w_left, w_left],\n",
    "        [0, h_left, 0     , h_left],\n",
    "        [1, 1     , 1     , 1     ]\n",
    "    ])\n",
    "\n",
    "    # apply the homography to the corner points to get projected corner points\n",
    "    Cp_left = H @ C_left\n",
    "    Cp_left = Cp_left / Cp_left[-1, :]\n",
    "\n",
    "    # find the minimum height and width of the projected corners\n",
    "    w_min, h_min = Cp_left[:-1].min(axis=1).tolist()\n",
    "    # we might need to properly floor or ceil the floats to prevent\n",
    "    # the edge pixels from getting cropped but this works for our needs\n",
    "    # feel free to fix this\n",
    "    w_min, h_min = int(np.abs(w_min)), int(np.abs(h_min))\n",
    "    # what's the final warped image size that can hold the full image?\n",
    "    warped_image_shape = (h_left + h_min, w_left + w_min)\n",
    "\n",
    "    # we create a new homography that applies the translation\n",
    "    # that would be otherwise cropped by the warp function below\n",
    "    Ht = np.array([\n",
    "        [1, 0, w_min],\n",
    "        [0, 1, h_min],\n",
    "        [0, 0, 1    ]\n",
    "    ])\n",
    "    # apply the translation homography so that the image is warped\n",
    "    # but does not have a negative translation relative to origin\n",
    "    Hw = Ht @ H\n",
    "    # may not be strictly necessary but make sure that (3,3) is 1\n",
    "    Hw = Hw / Hw[-1, -1]\n",
    "\n",
    "    # use skimage.transform.ProjectiveTransform to create a transform for the homography Hw\n",
    "    tform = ProjectiveTransform(Hw)#\n",
    "    # use skimage.transform.warp to apply the transform\n",
    "    warped_image = warp(image_left, tform.inverse, output_shape=warped_image_shape)#\n",
    "\n",
    "    return warped_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oqZeGP44i4JH"
   },
   "outputs": [],
   "source": [
    "img1_np = np.array(img1)\n",
    "print(img1_np.shape)\n",
    "warped_img1 = warp_img(img1_np, H)\n",
    "plt.imshow(warped_img1, cmap='gray')\n",
    "print(warped_img1.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "8sRIVohslBIR"
   },
   "source": [
    "## 8. Create a new image to hold the panorama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nq212KVlfS14"
   },
   "outputs": [],
   "source": [
    "def create_panorama(warped_img1, img2):\n",
    "    img2 = np.array(img2)\n",
    "    h1, w1 = warped_img1.shape\n",
    "    h2, w2 = img2.shape\n",
    "    print(h2, w2)\n",
    "    offset_h, offset_w = h1-h2, w1-w2\n",
    "    \n",
    "    Ht = np.array([\n",
    "        [1, 0, offset_w],\n",
    "        [0, 1, offset_h],\n",
    "        [0, 0, 1    ]\n",
    "    ])\n",
    "    warped_image_shape = (h2+offset_h, w2 + offset_w)\n",
    "    print(warped_image_shape)\n",
    "\n",
    "    tform = ProjectiveTransform(Ht)#\n",
    "    # use skimage.transform.warp to apply the transform\n",
    "    warped_image = warp(img2, tform.inverse, output_shape = warped_image_shape)#\n",
    "    warped_image[:h1, :w1] += warped_img1\n",
    "    return warped_image\n",
    "\n",
    "\n",
    "# create a panorama in gray scale first\n",
    "panorama_gray = create_panorama(warped_img1, img2)\n",
    "plt.imshow(panorama_gray, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lhgcLBIjoWjV"
   },
   "outputs": [],
   "source": [
    "# then create a color image by doing the same for each channel\n",
    "\n",
    "def create_panorama_rgb(img1, img2):\n",
    "    img1 = np.array(img1)\n",
    "    img2 = np.array(img2)\n",
    "\n",
    "    panorama_r = create_panorama(img1[..., 0], img2[..., 0])\n",
    "    panorama_g = create_panorama(img1[..., 1], img2[..., 1])\n",
    "    panorama_b = create_panorama(img1[..., 2], img2[..., 2])\n",
    "\n",
    "    # Stack all the channels together\n",
    "    panorama = np.stack([panorama_r, panorama_g, panorama_b], axis=-1)\n",
    "\n",
    "    return panorama\n",
    "\n",
    "img1_color = img1_float\n",
    "img2_color = img2_float\n",
    "panorama = create_panorama_rgb(img1_color, img2_color)\n",
    "plt.imshow(panorama)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
